# Joint Distributions

$\mathbb{P}(x \in A, y \in B) = \int_A \int_B f(x,y) dy dx$

## Marginals

$\mathbb{P}(x \in A) = \mathbb{P}(x \in A, y \in (-\infty, \infty)) = \int_A \int_{-\infty}^{\infty} f(x,y) dy dx$

$\mathbb{P}(y \in B) = \mathbb{P}(x \in (-\infty, \infty), y \in B) = \int_{-\infty}^{\infty} \int_B  f(x,y) dy dx$

## Independence

$F(x,y)=F_X(x)F_Y(y) \quad \forall x,y$

### Minimum & Maximum

Max: $F_{\text{Max}}(t)=\mathbb{P}(\text{Max} \leq t) = \mathbb{P}(x \leq t, y \leq t) \rightarrow$ use independence $\rightarrow = F_X(t)F_Y(t)$

Min: $1-F_{\text{Max}}$

## Sums of Independent Random Variables

### Distributions

Convolution (CDF): $ F_{X+Y}(a) = \mathbb{P}(X+Y \leq a) = \int_{-\infty}^\infty F_X (a-y) f_Y (y) dy $

Density (PDF): $ f_{X+Y} = \int_{-\infty}^\infty f_X (a-y) f_Y (y) dy $

### Uniform

### Normal

The sum of $n$ normal RVs $ \sum_i^n X_i $ is normally distributed with parameters:

$\mu = \sum_i^n \mu_i $

$\sigma^2 = \sum_i^n \sigma_i^2 $

$\sigma = \sqrt{\sum_i^n \sigma_i^2} \neq \sum_i^n \sqrt{\sigma_i^2} $

### Gamma

### Poisson

$X_1\sim\text{Poisson}(\lambda_1)$

$X_2\sim\text{Poisson}(\lambda_2)$

$Y = X_1+Y_2$

$Y\sim\text{Poisson}(\lambda= \lambda_1 + \lambda_2)$

$\mathbb{P}(X_1+X_2=n) = \frac{1}{n!} e^{-(\lambda_1+\lambda_2)} (\lambda_1 + \lambda_2)^n$

### Binomial 

$X_1\sim\text{Binom}(n,p)$

$X_2\sim\text{Binom}(m,p)$

$Y = X_1+Y_2$

$Y\sim\text{Binom}(n+m,p)$

$\mathbb{P}(X_1+X_2=k) = \binom{n+m}{k} = \sum_{i=0}^n \binom{n}{i} \binom{m}{k-i}$

### Geometric

## Conditional Distributions

### Discrete

### Continuous



## Order Statistics

## Joint Distributions of Functions

### The Jacobian