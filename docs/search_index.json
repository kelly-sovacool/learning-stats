[
["index.html", "Stats Reference Preface", " Stats Reference Kelly Sovacool 2018 Preface A reference for concepts &amp; equations in introductory statistics. The source code is hosted on GitHub. I used Sean Kross’ bookdown starter kit to begin creating this R Markdown book. "],
["calculus-review.html", "1 Calculus Review 1.1 Logarithms 1.2 Derivative &amp; Integration rules", " 1 Calculus Review 1.1 Logarithms \\(\\log_b a = x \\leftrightarrow b^x = a\\) \\(e^{c \\ln x} = x^c\\) 1.2 Derivative &amp; Integration rules Derivative Integral \\(\\frac{d}{dx} x^n = nx^{n-1}\\) \\(\\int x^n dx= \\frac{x^{n+1}}{n+1}+c\\) \\(\\frac{d}{dx} n^x = n^x \\ln x\\) \\(\\int n^x dx = \\frac{n^x}{\\ln n} + c\\) \\(\\frac{d}{dx} \\ln x = \\frac{1}{x}\\) \\(\\int \\frac{1}{ax+b} dx = \\frac{1}{a} \\ln|ax+b| +c\\) \\(\\frac{d}{dx} e^x = e^x\\) \\(\\int e^x dx = e^x + c\\) \\(\\frac{d}{dx} \\sin x = cos x\\) \\(\\int \\sin x dx = -\\cos x + c\\) \\(\\frac{d}{dx} \\cos x = -\\sin x\\) \\(\\int \\cos x dx = \\sin x + c\\) \\(\\frac{d}{dx} \\tan x = \\sec^2 x\\) \\(\\int \\tan x = \\ln|\\sec x| + c\\) \\(\\int f(x) \\pm g(x) dx = \\int f(x) dx \\pm \\int g(x) dx\\) \\(\\int x f(x) = x F(x) + f(x)\\) 1.2.1 Integration by substitution \\(u = g(x)\\) \\(\\int_a^b f(g(x)) g&#39;(x) dx = \\int_{g(a)}^{g(b)} f(u) du\\) 1.2.2 Integration by parts Assign \\(u\\) and \\(dv\\), differentiate \\(u\\) to find \\(du\\), integrate \\(dv\\) to find \\(v\\), then solve: \\(\\int_a^b u dv = \\left[uv\\right]_a^b - \\int_a^bvdu\\) "],
["probability.html", "2 Probability 2.1 Axioms 2.2 Union Rule 2.3 De Morgan’s Laws 2.4 Conditional Probability 2.5 Bayes’ Theorem 2.6 Independence 2.7 Counting Examples", " 2 Probability 2.1 Axioms \\(\\mathbb{P}(A) \\geq 0 \\quad \\forall A \\subset S\\) \\(\\mathbb{P}(S) = 1\\) If \\(A \\cap B = \\emptyset\\), then \\(\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B)\\) 2.2 Union Rule \\(\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cup B)\\) 2.3 De Morgan’s Laws \\((A \\cup B)^c = A^c \\cap B^c\\) \\((A \\cap B)^c = A^c \\cup B^c\\) 2.4 Conditional Probability \\(\\mathbb{P}(A|B) = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(B)}\\) \\(\\mathbb{P}(A) = \\mathbb{P}(A|B)\\mathbb{P}(B) + \\mathbb{P}(A|B^c)\\mathbb{P}(B^c)\\) 2.5 Bayes’ Theorem \\(\\mathbb{P}(B|A) = \\frac{\\mathbb{P}(A|B)\\mathbb{P}(B)}{\\mathbb{P}(A)}\\) 2.6 Independence \\(\\mathbb{P}(A|B) = \\mathbb{P}(A)\\) 2.7 Counting Examples There are \\(n!\\) ways to arrange \\(n\\) distinct elements in an ordered list. There are \\(6^n\\) outcomes for \\(n\\) tosses of a \\(6\\)-sided die. "],
["distributions-of-random-variables.html", "3 Distributions of Random Variables 3.1 Discrete 3.2 Continuous 3.3 Properties of Density Functions 3.4 Properties of Distribution Functions 3.5 Parameters 3.6 Distribution of a Function", " 3 Distributions of Random Variables 3.1 Discrete CDF: \\(\\displaystyle\\sum_{k=0}^i p(k)\\) 3.1.1 Bernoulli \\(X\\sim\\text{Bern}(p)\\) \\(\\mathbb{E}[X] = p\\) \\(\\text{Var}[X] = p(1-p)\\) \\[\\begin{equation}\\begin{aligned} p(x) = \\begin{cases} p &amp; x=1 \\\\ 1-p &amp; x=0 \\\\ 0 &amp; else \\end{cases}\\end{aligned}\\end{equation}\\] 3.1.2 Binomial \\(X\\sim\\text{Binom}(n,p)\\) \\(\\mathbb{E}[X] = np\\) \\(\\text{Var}[X] = np(1-p)\\) \\[p(k) = \\binom{n}{k} p^k (1-p)^{n-k}\\] 3.1.3 Poisson \\(X\\sim\\text{Poisson}(\\lambda\\sim np)\\) \\(\\mathbb{E}[X] = \\lambda\\) \\(\\text{Var}[X] = \\lambda\\) \\[p(k) = e^{-\\lambda} \\frac{\\lambda^k}{k!}\\] Approximation to binomial when \\(n \\rightarrow \\infty\\) and \\(p \\rightarrow 0\\). E.g. number of misprints per page of a book. 3.1.4 Geometric \\(X\\sim\\text{Geom}(p)\\) \\(\\mathbb{E}[X] = \\frac{1}{p}\\) \\(\\text{Var}[X] = \\frac{1-p}{p^2}\\) \\[\\begin{equation}\\begin{aligned} p(k) &amp;= (1-p)^{k-1} \\\\ \\\\ F(k) &amp;= 1-(1-p)^k \\\\ \\end{aligned}\\end{equation}\\] Experiment with infinite trials; stop at first success. Memoryless. E.g. flip a coin until heads comes up. 3.2 Continuous 3.2.1 Uniform \\(X\\sim\\text{Unif}(a,b)\\) \\(\\mathbb{E}[X] = \\frac{b+a}{2}\\) \\(\\text{Var}[X] = \\frac{(b-a)^2}{12}\\) \\[\\begin{equation}\\begin{aligned} f(x) &amp;= \\begin{cases} \\frac{1}{b-a} &amp; x \\in [a,b] \\\\ 0 &amp; \\text{else} \\\\ \\end{cases} \\\\ \\\\ F(x) &amp;= \\begin{cases} \\frac{x-a}{b-a} &amp; x \\in [a,b] \\\\ 0 &amp; \\text{else} \\end{cases}\\end{aligned}\\end{equation}\\] Simplest continuous distribution. All outcomes equally likely. E.g. pick random point on disk of radius \\(r\\). \\(x\\) is distance to center. \\(f(x) = \\frac{2x}{r^2}\\) when \\(0 \\leq x \\leq r\\). 3.2.2 General Normal \\(X\\sim\\text{N}(\\mu,\\sigma)\\) \\(\\mathbb{E}[X] = \\mu\\) \\(\\text{Var}[X] = \\sigma^2\\) \\[\\begin{equation}\\begin{aligned} f(x) &amp;= \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-(x-\\mu)^2/2\\sigma^2} \\\\ \\\\ F(x) &amp;= \\phi(Z=\\frac{x-\\mu}{\\sigma}) \\end{aligned}\\end{equation}\\] To find CDF, convert to standard normal, then use Z table. E.g. biological variables. E.g. exam scores. 3.2.2.1 Normal Approximation to the Binomial Distribution When \\(X\\sim\\text{Binom}(n,p)\\), \\(n \\rightarrow \\infty\\), &amp; \\(p \\rightarrow \\frac{1}{2}\\): \\(\\mathbb{E}[X] = np = \\mu\\), \\(\\sigma = \\sqrt{np(1-p)}\\), \\(z = \\frac{x-np}{\\sqrt{np(1-p)}}\\) \\(F_z(a) \\rightarrow \\phi (a)\\) \\(\\mathbb{P}(a \\leq z \\leq b) \\approx \\phi (b) - \\phi (a)\\) via De Maivre-Laplace Central Limit Theorem 3.2.3 Standard Normal \\(X\\sim\\text{N}(0,1)\\) \\(\\mathbb{E}[X] = 0\\) \\(\\text{Var}[X] = 1\\) \\[\\begin{equation}\\begin{aligned} f(x) &amp;= \\frac{1}{\\sqrt{2\\pi}} e^{-(x^2)/2} \\\\ \\\\ F(x) &amp;= \\phi(x) \\end{aligned}\\end{equation}\\] To find CDF, use Z table. Special case of the normal with no parameters. 3.2.4 Exponential \\(X\\sim\\text{Exp}(\\lambda)\\) \\(\\mathbb{E}[X] = \\frac{1}{\\lambda}\\) \\(\\text{Var}[X] = \\frac{1}{\\lambda^2}\\) \\[\\begin{equation}\\begin{aligned} f(x) &amp;= \\begin{cases} \\lambda e^{-\\lambda x} &amp; x &gt; 0 \\\\ 0 &amp; else \\\\ \\end{cases} \\\\ \\\\ F(x) &amp;= \\begin{cases} 1-e^{-\\lambda x} &amp; x &gt; 0 \\\\ 0 &amp; else \\end{cases} \\end{aligned}\\end{equation}\\] Memoryless. \\(\\lambda=\\) rate. Continuous version of Geom(\\(p\\)). 3.2.5 Gamma \\(X\\sim\\Gamma[\\alpha,\\lambda]\\) \\(\\mathbb{E}[X] = \\frac{\\alpha}{\\lambda}\\) \\(\\text{Var}[X] = \\frac{\\alpha}{\\lambda^2}\\) 3.2.6 Chi Square \\(X\\sim\\chi^2[n]\\) \\(\\mathbb{E}[X] = n\\) \\(\\text{Var}[X] = 2n\\) Special case of \\(\\Gamma\\) where \\(\\alpha=\\frac{n}{2}\\) and \\(\\lambda=\\frac{1}{2}\\). 3.3 Properties of Density Functions PMF: \\(p(k) \\quad\\) PDF: \\(f(x)\\) Derivative of the distribution function. Nonnegative everywhere. Integral over its domain is \\(1\\): \\(\\int_a^b f(x)=1\\) 3.4 Properties of Distribution Functions CDF: \\(F(x)\\) \\(\\lim_{x\\rightarrow -\\infty} F(x) = 0\\) \\(\\lim_{x\\rightarrow +\\infty} F(x) = 1\\) Nondecreasing. 3.5 Parameters Discrete: \\(\\mathbb{E}[X] = \\mu = \\sum_{i=1}^k x_i p_i\\) Continuous: \\(\\mathbb{E}[X] = \\mu = \\int_{-\\infty}^{\\infty} x f(x) dx\\) Law of total expectation: \\(\\mathbb{E}[X] = \\sum_j \\mathbb{E}(E|F_j)\\mathbb{P}(F_j)\\) \\(\\text{Var}[X] = \\mathbb{E}(X^2) - \\mathbb{E}(X)^2 = \\sigma^2\\) \\(\\sigma = \\sqrt{\\text{Var}[X]}\\) \\(Z = \\frac{x-\\mu}{\\sigma}\\), \\(Z\\sim~\\text{N}(0,1)\\) 3.6 Distribution of a Function \\(X\\) is a random variable. \\(Y=g(x)\\) is a function of \\(X\\). 3.6.1 Transformation Method If \\(Y=g(x)\\) is monotonic: \\(f_Y(y)=\\frac{1}{|g&#39;(x)|}f_X(x)\\) Integrate \\(f_Y\\) to find \\(F_Y\\). 3.6.2 CDF Method Must use when \\(Y=g(x)\\) is not monotonic: \\(F_Y(y)=\\mathbb{P}(Y \\leq y) = \\mathbb{P}(g(x) \\leq y) \\rightarrow\\) solve for \\(x\\) and frame in terms of \\(F_X(y)\\). Differentiate \\(F_Y\\) to find \\(f_Y\\). 3.6.3 Special case: Hazard &amp; Survival Survival: \\(S_T(t) = \\mathbb{P}(T&gt;t) = 1 - \\mathbb{P}(T \\leq t) = 1 - F_T(t) = e^{-\\int_{u=o}^t \\lambda(u) du}\\) Density: \\(f_T(t) = F_T&#39;(t) = -S_T&#39;(t)\\) Hazard: \\(\\lambda(t) = \\frac{f_T(t)}{S_T(t)} = \\frac{-S_T&#39;(t)}{S_T(t)} = -\\frac{d}{dt} \\log S_T(t)\\) "],
["joint-distributions.html", "4 Joint Distributions 4.1 Marginals 4.2 Independence 4.3 Sums of Independent Random Variables 4.4 Conditional Distributions 4.5 Order Statistics 4.6 Joint Distributions of Functions", " 4 Joint Distributions \\(\\mathbb{P}(x \\in A, y \\in B) = \\int_A \\int_B f(x,y) dy dx\\) 4.1 Marginals \\(\\mathbb{P}(x \\in A) = \\mathbb{P}(x \\in A, y \\in (-\\infty, \\infty)) = \\int_A \\int_{-\\infty}^{\\infty} f(x,y) dy dx\\) \\(\\mathbb{P}(y \\in B) = \\mathbb{P}(x \\in (-\\infty, \\infty), y \\in B) = \\int_{-\\infty}^{\\infty} \\int_B f(x,y) dy dx\\) 4.2 Independence \\(F(x,y)=F_X(x)F_Y(y) \\quad \\forall x,y\\) 4.2.1 Minimum &amp; Maximum Max: \\(F_{\\text{Max}}(t)=\\mathbb{P}(\\text{Max} \\leq t) = \\mathbb{P}(x \\leq t, y \\leq t) \\rightarrow\\) use independence \\(\\rightarrow = F_X(t)F_Y(t)\\) Min: \\(1-F_{\\text{Max}}\\) 4.3 Sums of Independent Random Variables 4.3.1 Distributions Convolution (CDF): \\(F_{X+Y}(a) = \\mathbb{P}(X+Y \\leq a) = \\int_{-\\infty}^\\infty F_X (a-y) f_Y (y) dy\\) Density (PDF): \\(f_{X+Y} = \\int_{-\\infty}^\\infty f_X (a-y) f_Y (y) dy\\) 4.3.2 Uniform 4.3.3 Normal The sum of \\(n\\) normal RVs \\(\\sum_i^n X_i\\) is normally distributed with parameters: \\(\\mu = \\sum_i^n \\mu_i\\) \\(\\sigma^2 = \\sum_i^n \\sigma_i^2\\) \\(\\sigma = \\sqrt{\\sum_i^n \\sigma_i^2} \\neq \\sum_i^n \\sqrt{\\sigma_i^2}\\) 4.3.4 Gamma 4.3.5 Poisson \\(X_1\\sim\\text{Poisson}(\\lambda_1)\\) \\(X_2\\sim\\text{Poisson}(\\lambda_2)\\) \\(Y = X_1+Y_2\\) \\(Y\\sim\\text{Poisson}(\\lambda= \\lambda_1 + \\lambda_2)\\) \\(\\mathbb{P}(X_1+X_2=n) = \\frac{1}{n!} e^{-(\\lambda_1+\\lambda_2)} (\\lambda_1 + \\lambda_2)^n\\) 4.3.6 Binomial \\(X_1\\sim\\text{Binom}(n,p)\\) \\(X_2\\sim\\text{Binom}(m,p)\\) \\(Y = X_1+Y_2\\) \\(Y\\sim\\text{Binom}(n+m,p)\\) \\(\\mathbb{P}(X_1+X_2=k) = \\binom{n+m}{k} = \\sum_{i=0}^n \\binom{n}{i} \\binom{m}{k-i}\\) 4.3.7 Geometric 4.4 Conditional Distributions 4.5 Order Statistics 4.6 Joint Distributions of Functions 4.6.1 The Jacobian "]
]
