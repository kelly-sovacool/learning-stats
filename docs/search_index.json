[
["index.html", "Stats Reference Preface", " Stats Reference Kelly Sovacool 2018-11-18 Preface A reference for concepts &amp; equations in introductory statistics. The source code is hosted on GitHub. I used Sean Krossâ€™ bookdown starter kit to begin creating this R Markdown book. "],
["distributions.html", "1 Distributions 1.1 Discrete 1.2 Continuous", " 1 Distributions 1.1 Discrete CDF: \\(\\displaystyle\\sum_{k=0}^i p(k)\\) 1.1.1 Bernoulli \\(X\\sim\\text{Bern}(p)\\) \\(\\mathbb{E}[X] = p\\) \\(\\text{Var}[X] = p(1-p)\\) \\[\\begin{equation}\\begin{aligned} p(x) = \\begin{cases} p &amp; x=1 \\\\ 1-p &amp; x=0 \\\\ 0 &amp; else \\end{cases}\\end{aligned}\\end{equation}\\] 1.1.2 Binomial \\(X\\sim\\text{Binom}(n,p)\\) \\(\\mathbb{E}[X] = np\\) \\(\\text{Var}[X] = np(1-p)\\) \\[p(k) = \\binom{n}{k} p^k (1-p)^{n-k}\\] 1.1.3 Poisson \\(X\\sim\\text{Poisson}(\\lambda\\sim np)\\) \\(\\mathbb{E}[X] = \\lambda\\) \\(\\text{Var}[X] = \\lambda\\) \\[p(k) = e^{-\\lambda} \\frac{\\lambda^k}{k!}\\] Approximation to binomial when \\(n \\rightarrow \\infty\\) and \\(p \\rightarrow 0\\). E.g. number of misprints per page of a book. 1.1.4 Geometric \\(X\\sim\\text{Geom}(p)\\) \\(\\mathbb{E}[X] = \\frac{1}{p}\\) \\(\\text{Var}[X] = \\frac{1-p}{p^2}\\) \\[\\begin{equation}\\begin{aligned} p(k) &amp;= (1-p)^{k-1} \\\\ \\\\ F(k) &amp;= 1-(1-p)^k \\\\ \\end{aligned}\\end{equation}\\] Experiment with infinite trials; stop at first success. Memoryless. E.g. flip a coin until heads comes up. 1.2 Continuous 1.2.1 Uniform \\(X\\sim\\text{Unif}(a,b)\\) \\(\\mathbb{E}[X] = \\frac{b+a}{2}\\) \\(\\text{Var}[X] = \\frac{(b-a)^2}{12}\\) \\[\\begin{equation}\\begin{aligned} f(x) &amp;= \\begin{cases} \\frac{1}{b-a} &amp; x \\in [a,b] \\\\ 0 &amp; \\text{else} \\\\ \\end{cases} \\\\ \\\\ F(x) &amp;= \\begin{cases} \\frac{x-a}{b-a} &amp; x \\in [a,b] \\\\ 0 &amp; \\text{else} \\end{cases}\\end{aligned}\\end{equation}\\] Simplest continuous distribution. All outcomes equally likely. E.g. pick random point on disk of radius \\(r\\). \\(x\\) is distance to center. \\(f(x) = \\frac{2x}{r^2}\\) when \\(0 \\leq x \\leq r\\). 1.2.2 General Normal \\(X\\sim\\text{N}(\\mu,\\sigma)\\) \\(\\mathbb{E}[X] = \\mu\\) \\(\\text{Var}[X] = \\sigma^2\\) \\[\\begin{equation}\\begin{aligned} f(x) &amp;= \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-(x-\\mu)^2/2\\sigma^2} \\\\ \\\\ F(x) &amp;= \\phi(Z=\\frac{x-\\mu}{\\sigma}) \\end{aligned}\\end{equation}\\] To find CDF, convert to standard normal, then use Z table. E.g. biological variables. E.g. exam scores. 1.2.3 Standard Normal \\(X\\sim\\text{N}(0,1)\\) \\(\\mathbb{E}[X] = 0\\) \\(\\text{Var}[X] = 1\\) \\[\\begin{equation}\\begin{aligned} f(x) &amp;= \\frac{1}{\\sqrt{2\\pi}} e^{-(x^2)/2} \\\\ \\\\ F(x) &amp;= \\phi(x) \\end{aligned}\\end{equation}\\] To find CDF, use Z table. Special case of the normal with no parameters. 1.2.4 Exponential \\(X\\sim\\text{Exp}(\\lambda)\\) \\(\\mathbb{E}[X] = \\frac{1}{\\lambda}\\) \\(\\text{Var}[X] = \\frac{1}{\\lambda^2}\\) \\[\\begin{equation}\\begin{aligned} f(x) &amp;= \\begin{cases} \\lambda e^{-\\lambda x} &amp; x &gt; 0 \\\\ 0 &amp; else \\\\ \\end{cases} \\\\ \\\\ F(x) &amp;= \\begin{cases} 1-e^{-\\lambda x} &amp; x &gt; 0 \\\\ 0 &amp; else \\end{cases} \\end{aligned}\\end{equation}\\] Memoryless. \\(\\lambda=\\) rate. Continuous version of Geom(\\(p\\)). 1.2.5 Gamma \\(X\\sim\\Gamma[\\alpha,\\lambda]\\) \\(\\mathbb{E}[X] = \\frac{\\alpha}{\\lambda}\\) \\(\\text{Var}[X] = \\frac{\\alpha}{\\lambda^2}\\) 1.2.6 Chi Square \\(X\\sim\\chi^2[n]\\) \\(\\mathbb{E}[X] = n\\) \\(\\text{Var}[X] = 2n\\) Special case of \\(\\Gamma\\) where \\(\\alpha=\\frac{n}{2}\\) and \\(\\lambda=\\frac{1}{2}\\). "],
["sums-of-independent-random-variables.html", "2 Sums of Independent Random Variables 2.1 Uniform 2.2 Normal 2.3 Gamma 2.4 Poisson 2.5 Binomial 2.6 Geometric", " 2 Sums of Independent Random Variables Convolution (CDF): \\(F_{X+Y}(a) = \\mathbb{P}(X+Y \\leq a) = \\int_{-\\infty}^\\infty F_X (a-y) f_Y (y) dy\\) Density (PDF): \\(f_{X+Y} = \\int_{-\\infty}^\\infty f_X (a-y) f_Y (y) dy\\) 2.1 Uniform 2.2 Normal The sum of \\(n\\) normal RVs \\(\\sum_i^n X_i\\) is normally distributed with parameters: \\(\\mu = \\sum_i^n \\mu_i\\) \\(\\sigma^2 = \\sum_i^n \\sigma_i^2\\) \\(\\sigma = \\sqrt{\\sum_i^n \\sigma_i^2} \\neq \\sum_i^n \\sqrt{\\sigma_i^2}\\) 2.3 Gamma 2.4 Poisson \\(X_1\\sim\\text{Poisson}(\\lambda_1)\\) \\(X_2\\sim\\text{Poisson}(\\lambda_2)\\) \\(Y = X_1+Y_2\\) \\(Y\\sim\\text{Poisson}(\\lambda= \\lambda_1 + \\lambda_2)\\) \\(\\mathbb{P}(X_1+X_2=n) = \\frac{1}{n!} e^{-(\\lambda_1+\\lambda_2)} (\\lambda_1 + \\lambda_2)^n\\) 2.5 Binomial \\(X_1\\sim\\text{Binom}(n,p)\\) \\(X_2\\sim\\text{Binom}(m,p)\\) \\(Y = X_1+Y_2\\) \\(Y\\sim\\text{Binom}(n+m,p)\\) \\(\\mathbb{P}(X_1+X_2=k) = \\binom{n+m}{k} = \\sum_{i=0}^n \\binom{n}{i} \\binom{m}{k-i}\\) 2.6 Geometric "]
]
